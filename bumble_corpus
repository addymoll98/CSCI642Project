from math import prod
import os, os.path
import string
import nltk, string, re
from nltk import FreqDist, NaiveBayesClassifier, classify
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.corpus.reader import CategorizedPlaintextCorpusReader
import random
from sklearn.metrics import classification_report
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification
from nltk.stem import WordNetLemmatizer

def remove_emoji(text):
    emoji_pattern = re.compile("["
            u"\U0001F600-\U0001F64F"  # emoticons
            u"\U0001F300-\U0001F5FF"  # symbols & pictographs
            u"\U0001F680-\U0001F6FF"  # transport & map symbols
            u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
            u"\U00002700-\U000027BF"  # Dingbats
            u"\U00002702-\U000027B0"
            u"\U000024C2-\U0001F251"
                               "]+", flags=re.UNICODE)
    return emoji_pattern.sub(r'', text) 

def remove_punc(text):
	punc = '''!()-[]{};:'"\,<>./?@#$%^&*_~'''
	for ele in text:
		if ele in punc:
			text = text.replace(ele, "")
	return text

bumble=CategorizedPlaintextCorpusReader('C:/Users/addym/AppData/Roaming/nltk_data/corpora/bumble',  \
                                 '.*', \
                                 cat_pattern=r'(.*)[/]')

print(bumble.categories())

documents = []

lemmatizer = WordNetLemmatizer()
punc = '''!()-[]{};:'"\,<>./?@#$%^&*_~'''

for category in bumble.categories():
	for fileid in bumble.fileids(category):
		for word in bumble.words(fileid):
			word=lemmatizer.lemmatize(word)
		for word in bumble.words(fileid):
			word=word.lower()
		for word in bumble.words(fileid):
			if word in punc:
				fileid.replace(word,'')
		if len(bumble.words(fileid)) > 9:
			documents.append((bumble.words(fileid), category))



stopwords_english = stopwords.words('english')

for document in documents:
	for word in document:
		if word in stopwords_english:
			document.remove(word)


all_words_clean=[]
for document in documents:
	docx,docy=document
	for word in docx:
		all_words_clean.append(word)

all_words_frequency = FreqDist(all_words_clean)

most_common_words = all_words_frequency.most_common(2000)

word_features = [item[0] for item in most_common_words]

def document_features(document):
	document_words = set(document)
	features = {}
	for word in word_features:
		features['contains(%s)' % word] = (word in document_words)
	return features

feature_set = [(document_features(doc), category) for (doc, category) in documents]
random.shuffle(feature_set)

train_set = feature_set[400:]
test_set = feature_set[:400]

NBclassifier = NaiveBayesClassifier.train(train_set)

#accuracy
accuracy = classify.accuracy(NBclassifier,test_set)
print(accuracy)

app_func=[]
app_func=[0 for i in range(3)]
cust_serv=[]
cust_serv=[0 for i in range(3)]
prod_sat=[]
prod_sat=[0 for i in range(3)]


y_true=[]
y_pred=[]

for document in test_set:
	x,y=document
	if y=="app_func":
		i=0
		y_true.append(0)
	elif y=="cust_serv":
		i=1
		y_true.append(1)
	elif y=="prod_sat":
		i=2
		y_true.append(2)
	this_class=NBclassifier.classify(x)
	if this_class=="app_func":
		app_func[i]=app_func[i]+1
		y_pred.append(0)
	elif this_class=="cust_serv":
		cust_serv[i]=cust_serv[i]+1
		y_pred.append(1)
	elif this_class=="prod_sat":
		prod_sat[i]=prod_sat[i]+1
		y_pred.append(2)

print(app_func)
print(cust_serv)
print(prod_sat)
target_names=['app_func', 'cust_serv', 'prod_sat']

print(classification_report(y_true,y_pred,target_names=target_names))




###All this is balancing the data

balanced_feature_set=feature_set

app_func=0
cust_serv=0
prod_sat=0
for member in balanced_feature_set:
	x,y=member
	if y=="app_func":
		app_func+=1
	elif y=="cust_serv":
		cust_serv+=1
	elif y=="prod_sat":
		prod_sat+=1

while app_func < prod_sat and cust_serv<prod_sat:
	for member in balanced_feature_set:
		x,y=member
		if y=="app_func":
			if app_func < prod_sat:
				balanced_feature_set.append((x,y))
				app_func+=1
		elif y=="cust_serv":
			if cust_serv < prod_sat:
				balanced_feature_set.append((x,y))
				cust_serv+=1

random.shuffle(balanced_feature_set)

balanced_train_set = balanced_feature_set[400:]
balanced_test_set = balanced_feature_set[:400]

NBclassifier = NaiveBayesClassifier.train(balanced_train_set)

#accuracy
accuracy = classify.accuracy(NBclassifier,balanced_test_set)
print(accuracy)

app_func=[]
app_func=[0 for i in range(3)]
cust_serv=[]
cust_serv=[0 for i in range(3)]
prod_sat=[]
prod_sat=[0 for i in range(3)]


y_true=[]
y_pred=[]

for document in balanced_test_set:
	x,y=document
	if y=="app_func":
		i=0
		y_true.append(0)
	elif y=="cust_serv":
		i=1
		y_true.append(1)
	elif y=="prod_sat":
		i=2
		y_true.append(2)
	this_class=NBclassifier.classify(x)
	if this_class=="app_func":
		app_func[i]=app_func[i]+1
		y_pred.append(0)
	elif this_class=="cust_serv":
		cust_serv[i]=cust_serv[i]+1
		y_pred.append(1)
	elif this_class=="prod_sat":
		prod_sat[i]=prod_sat[i]+1
		y_pred.append(2)

print(app_func)
print(cust_serv)
print(prod_sat)
target_names=['app_func', 'cust_serv', 'prod_sat']

print(classification_report(y_true,y_pred,target_names=target_names))
